# ìë™ ë°±ì—… ì‹œìŠ¤í…œ ê°€ì´ë“œ

## ğŸ“‹ ê°œìš”

Cloudflare D1 ë°ì´í„°ë² ì´ìŠ¤ì˜ ìë™ ë°±ì—… ë° ë³µêµ¬ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

## ğŸ¯ ë°±ì—… ì „ëµ

### ë°±ì—… ì¢…ë¥˜
1. **ìë™ ì¼ì¼ ë°±ì—…** (Cloudflare Cron Trigger)
2. **ìˆ˜ë™ ë°±ì—…** (wrangler CLI)
3. **ë°°í¬ ì „ ë°±ì—…** (CI/CD í†µí•©)

### ë°±ì—… ë³´ì¡´ ì •ì±…
- ì¼ì¼ ë°±ì—…: 7ì¼ ë³´ì¡´
- ì£¼ê°„ ë°±ì—…: 4ì£¼ ë³´ì¡´
- ì›”ê°„ ë°±ì—…: 12ê°œì›” ë³´ì¡´

## ğŸ”§ ë°±ì—… êµ¬í˜„

### 1. D1 Export API ì‚¬ìš©

**ë°±ì—… ìŠ¤í¬ë¦½íŠ¸ (scripts/backup-d1.sh):**
```bash
#!/bin/bash
# D1 Database Backup Script

DATABASE_NAME="gallerypia-production"
DATABASE_ID="your-database-id"
BACKUP_DIR="./backups"
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="${BACKUP_DIR}/backup_${TIMESTAMP}.sql"

# Create backup directory
mkdir -p "${BACKUP_DIR}"

# Export database to SQL file
echo "ğŸ”„ Backing up ${DATABASE_NAME}..."
npx wrangler d1 export ${DATABASE_NAME} --output="${BACKUP_FILE}"

# Compress backup
gzip "${BACKUP_FILE}"
echo "âœ… Backup completed: ${BACKUP_FILE}.gz"

# Upload to R2 storage
npx wrangler r2 object put gallerypia-backups/backup_${TIMESTAMP}.sql.gz --file="${BACKUP_FILE}.gz"
echo "â˜ï¸ Backup uploaded to R2 storage"

# Clean old backups (keep last 7 days)
find "${BACKUP_DIR}" -name "backup_*.sql.gz" -mtime +7 -delete
echo "ğŸ§¹ Cleaned old backups"
```

### 2. Cloudflare Workers Cron ì„¤ì •

**wrangler.jsonc:**
```jsonc
{
  "name": "gallerypia",
  "d1_databases": [
    {
      "binding": "DB",
      "database_name": "gallerypia-production",
      "database_id": "your-database-id"
    }
  ],
  "r2_buckets": [
    {
      "binding": "BACKUP_BUCKET",
      "bucket_name": "gallerypia-backups"
    }
  ],
  "triggers": {
    "crons": ["0 2 * * *"]  // ë§¤ì¼ ìƒˆë²½ 2ì‹œ (UTC)
  }
}
```

**Cron Job Handler (src/cron/backup.ts):**
```typescript
import type { Context } from 'hono'

export async function scheduledBackup(c: Context) {
  const env = c.env
  const timestamp = new Date().toISOString().replace(/[:.]/g, '-')
  const backupKey = `backup_${timestamp}.sql`
  
  try {
    // D1 Database Export
    const tables = await env.DB.prepare(`
      SELECT name FROM sqlite_master 
      WHERE type='table' 
      AND name NOT LIKE 'sqlite_%'
    `).all()
    
    let sqlDump = '-- GalleryPia Database Backup\n'
    sqlDump += `-- Timestamp: ${timestamp}\n\n`
    
    for (const table of tables.results) {
      const tableName = table.name
      
      // Export table schema
      const schema = await env.DB.prepare(`
        SELECT sql FROM sqlite_master 
        WHERE type='table' AND name=?
      `).bind(tableName).first()
      
      sqlDump += `${schema.sql};\n\n`
      
      // Export table data
      const rows = await env.DB.prepare(`SELECT * FROM ${tableName}`).all()
      
      for (const row of rows.results) {
        const columns = Object.keys(row).join(', ')
        const values = Object.values(row)
          .map(v => typeof v === 'string' ? `'${v.replace(/'/g, "''")}'` : v)
          .join(', ')
        
        sqlDump += `INSERT INTO ${tableName} (${columns}) VALUES (${values});\n`
      }
      
      sqlDump += '\n'
    }
    
    // Upload to R2
    await env.BACKUP_BUCKET.put(backupKey, sqlDump, {
      httpMetadata: {
        contentType: 'application/sql'
      },
      customMetadata: {
        database: 'gallerypia-production',
        timestamp: timestamp
      }
    })
    
    console.log(`âœ… Backup completed: ${backupKey}`)
    return { success: true, backup: backupKey }
    
  } catch (error) {
    console.error('âŒ Backup failed:', error)
    throw error
  }
}
```

**ë©”ì¸ ì•± í†µí•© (src/index.tsx):**
```typescript
import { scheduledBackup } from './cron/backup'

export default {
  async fetch(request: Request, env: any): Promise<Response> {
    return app.fetch(request, env)
  },
  
  async scheduled(event: ScheduledEvent, env: any, ctx: ExecutionContext) {
    // Cron trigger í•¸ë“¤ëŸ¬
    ctx.waitUntil(scheduledBackup({ env } as Context))
  }
}
```

## ğŸ“¥ ë³µêµ¬ ì ˆì°¨

### 1. ìˆ˜ë™ ë³µêµ¬

**ë¡œì»¬ ë³µêµ¬:**
```bash
# Download backup from R2
npx wrangler r2 object get gallerypia-backups/backup_20241124_020000.sql.gz --file=restore.sql.gz

# Decompress
gunzip restore.sql.gz

# Restore to local database
npx wrangler d1 execute gallerypia-production --local --file=restore.sql
```

**í”„ë¡œë•ì…˜ ë³µêµ¬:**
```bash
# âš ï¸ WARNING: This will overwrite production data
npx wrangler d1 execute gallerypia-production --file=restore.sql
```

### 2. ìë™ ë³µêµ¬ ìŠ¤í¬ë¦½íŠ¸

**scripts/restore-d1.sh:**
```bash
#!/bin/bash
# D1 Database Restore Script

if [ $# -eq 0 ]; then
    echo "Usage: ./restore-d1.sh <backup-file.sql.gz>"
    exit 1
fi

BACKUP_FILE=$1
TEMP_SQL="temp_restore.sql"

# Decompress
gunzip -c "${BACKUP_FILE}" > "${TEMP_SQL}"

# Ask for confirmation
read -p "âš ï¸ This will restore from ${BACKUP_FILE}. Continue? (yes/no): " confirm
if [ "$confirm" != "yes" ]; then
    echo "âŒ Restore cancelled"
    rm "${TEMP_SQL}"
    exit 0
fi

# Restore
echo "ğŸ”„ Restoring database..."
npx wrangler d1 execute gallerypia-production --file="${TEMP_SQL}"

# Cleanup
rm "${TEMP_SQL}"
echo "âœ… Restore completed"
```

### 3. ë³µêµ¬ ê²€ì¦

**scripts/verify-backup.sh:**
```bash
#!/bin/bash
# Verify backup integrity

BACKUP_FILE=$1

echo "ğŸ” Verifying backup: ${BACKUP_FILE}"

# Decompress and check SQL syntax
gunzip -c "${BACKUP_FILE}" | sqlite3 :memory: ".read /dev/stdin" ".schema"

if [ $? -eq 0 ]; then
    echo "âœ… Backup is valid"
else
    echo "âŒ Backup is corrupted"
    exit 1
fi

# Count tables
TABLE_COUNT=$(gunzip -c "${BACKUP_FILE}" | grep -c "CREATE TABLE")
echo "ğŸ“Š Tables found: ${TABLE_COUNT}"

# Check for data
INSERT_COUNT=$(gunzip -c "${BACKUP_FILE}" | grep -c "INSERT INTO")
echo "ğŸ“Š Insert statements: ${INSERT_COUNT}"
```

## ğŸ“Š ë°±ì—… ëª¨ë‹ˆí„°ë§

### Backup Status API

**API ì—”ë“œí¬ì¸íŠ¸ (src/routes/admin.tsx):**
```typescript
app.get('/api/admin/backups', async (c) => {
  const env = c.env
  
  // List backups from R2
  const backups = await env.BACKUP_BUCKET.list({
    prefix: 'backup_'
  })
  
  const backupList = backups.objects.map(obj => ({
    key: obj.key,
    size: obj.size,
    uploaded: obj.uploaded,
    age: Math.floor((Date.now() - new Date(obj.uploaded).getTime()) / 86400000)
  }))
  
  return c.json({
    total: backupList.length,
    backups: backupList,
    oldest: backupList[backupList.length - 1]?.uploaded,
    newest: backupList[0]?.uploaded
  })
})

app.post('/api/admin/backup/trigger', async (c) => {
  // Manual backup trigger
  const result = await scheduledBackup(c)
  return c.json(result)
})
```

## ğŸ”„ CI/CD í†µí•©

**.github/workflows/backup-before-deploy.yml:**
```yaml
name: Backup Before Deploy

on:
  push:
    branches: [main]

jobs:
  backup:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
      
      - name: Install Wrangler
        run: npm install -g wrangler
      
      - name: Backup Database
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
        run: |
          TIMESTAMP=$(date +%Y%m%d_%H%M%S)
          wrangler d1 export gallerypia-production --output=backup_pre_deploy_${TIMESTAMP}.sql
          gzip backup_pre_deploy_${TIMESTAMP}.sql
          wrangler r2 object put gallerypia-backups/deploy/backup_pre_deploy_${TIMESTAMP}.sql.gz --file=backup_pre_deploy_${TIMESTAMP}.sql.gz
```

## ğŸ“‹ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ì¼ì¼ ì‘ì—…
- [ ] ìë™ ë°±ì—… ì„±ê³µ í™•ì¸ (Cloudflare Dashboard â†’ Workers â†’ Logs)
- [ ] R2 ë²„í‚·ì— ìƒˆ ë°±ì—… íŒŒì¼ í™•ì¸

### ì£¼ê°„ ì‘ì—…
- [ ] ë°±ì—… ë¬´ê²°ì„± ê²€ì¦ (`verify-backup.sh`)
- [ ] ë³µêµ¬ í…ŒìŠ¤íŠ¸ (ë¡œì»¬ í™˜ê²½)
- [ ] ì˜¤ë˜ëœ ë°±ì—… ì •ë¦¬ í™•ì¸

### ì›”ê°„ ì‘ì—…
- [ ] í”„ë¡œë•ì…˜ ë³µêµ¬ í…ŒìŠ¤íŠ¸ (ìŠ¤í…Œì´ì§• í™˜ê²½)
- [ ] ë°±ì—… ì •ì±… ê²€í† 
- [ ] ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§

## ğŸš¨ ë¹„ìƒ ë³µêµ¬ ì ˆì°¨

### ë°ì´í„° ì†ì‹¤ ì‹œë‚˜ë¦¬ì˜¤

1. **ì¦‰ì‹œ ì¡°ì¹˜**
   - ì„œë¹„ìŠ¤ ì¤‘ë‹¨ (ë°°í¬ ë¡¤ë°± ë˜ëŠ” ì ê²€ ëª¨ë“œ)
   - ìµœì‹  ë°±ì—… íŒŒì¼ í™•ì¸

2. **ë³µêµ¬ ì‹¤í–‰**
   ```bash
   # ìµœì‹  ë°±ì—… ë‹¤ìš´ë¡œë“œ
   npx wrangler r2 object get gallerypia-backups/$(npx wrangler r2 object list gallerypia-backups | head -1) --file=latest.sql.gz
   
   # ë³µêµ¬
   ./scripts/restore-d1.sh latest.sql.gz
   ```

3. **ê²€ì¦**
   ```bash
   # ë°ì´í„° ë¬´ê²°ì„± í™•ì¸
   curl https://gallerypia.pages.dev/api/admin/health
   
   # ë ˆì½”ë“œ ìˆ˜ í™•ì¸
   npx wrangler d1 execute gallerypia-production --command="SELECT COUNT(*) FROM users"
   ```

4. **ì„œë¹„ìŠ¤ ì¬ê°œ**
   - ë³µêµ¬ ì™„ë£Œ í™•ì¸
   - ì„œë¹„ìŠ¤ ì¬ì‹œì‘
   - ëª¨ë‹ˆí„°ë§ ê°•í™”

## ğŸ“š ì°¸ê³  ìë£Œ

- [Cloudflare D1 Documentation](https://developers.cloudflare.com/d1/)
- [Cloudflare R2 Documentation](https://developers.cloudflare.com/r2/)
- [Cron Triggers](https://developers.cloudflare.com/workers/platform/triggers/cron-triggers/)
